

services:
  pyspark:
    container_name: pyspark
    # image: ghcr.io/apache/spark-docker/spark:3.5.0-python3
    build:
      context: .
      dockerfile: Spark.Dockerfile
    tty: true
    ## command to run bash script using sh then use bash terminal:
    command: [ "/bin/bash", "-c", "cd /opt/spark/crosspipe && sh /opt/spark/crosspipe/wod.sh && /bin/bash" ]


    # command: [ "sh", "/opt/spark/python/pyspark/startup.sh" ]
    # command: [ "/opt/spark/bin/pyspark" ]
    # command: [ "/opt/spark/bin/spark-submit", "/opt/spark/python/pyspark/inject.py" ]
    # command: [ "python3", "/opt/spark/python/pyspark/start_inject.py" ]
    ## python3 /opt/spark/python/pyspark/start_inject.py
    # command: [""]
    volumes:
      # - ./inject.py:/opt/spark/python/pyspark/inject.py:ro
      # - ./start_inject.py:/opt/spark/python/pyspark/start_inject.py:ro
      # - ./start_inject.sh:/opt/spark/python/pyspark/start_inject.sh:ro
      # - ./startup.sh:/opt/spark/python/pyspark/startup.sh:ro
      - ./src/crosspipe/:/opt/spark/crosspipe/:ro
    environment:
      SPARK_DRIVER_MEMORY: 2 # In GB
      JDBC_OMOP_URL: "jdbc:postgresql://omop-pg:5432/omop_yourorg"
      JDBC_OMOP_USERNAME: "omopuser"
      JDBC_OMOP_PASSWORD: "P@ssw0rd"
      JDBC_OMOP_SCHEMA_CDM: "synthea"
      JDBC_OMOP_SCHEMA_VOCAB: "vocab"

      JDBC_ATLAS_URL: "jdbc:postgresql://ohdsi-webapi-pg:5432/webtools"
      JDBC_ATLAS_USERNAME: "postgres"
      JDBC_ATLAS_PASSWORD: "mypass"
      JDBC_ATLAS_SCHEMA_CDM: "cdm"
      JDBC_ATLAS_SCHEMA_VOCAB: "vocab"

      JDBC_CROSSPIPE_URL: "jdbc:postgresql://crosspipe-pg:5432/crosspipe"
      JDBC_CROSSPIPE_USERNAME: "crosspipe"
      JDBC_CROSSPIPE_PASSWORD: "P@ssw0rd"
      JDBC_CROSSPIPE_SCHEMA_CDM: "cdm"
      JDBC_CROSSPIPE_SCHEMA_VOCAB: "vocab"
    
    networks:
      - omop-cloudbuild

networks:
  omop-cloudbuild:
    external: true
    name: omop-cloudbuild # Needed for Continuous integration